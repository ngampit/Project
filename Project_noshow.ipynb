{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__author__ = \"ngampit sutthsailp\" \n",
    "__email__ = \"ngampitt@yahoo.com\"\n",
    "__Linkedin__ = \"Ngampit(Molly)Sutthsilp\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Medical Appointment Noshow (Kaggle)\n",
    "\n",
    "\n",
    "1. [Introduction](#intro)\n",
    "2. [Data Wrangling](#data)\n",
    "3. [Data Cleaning](#cleaning)\n",
    "4. [Exploratory Data Analysis](#EDA)\n",
    "5. [Perfomance evaluation method](#performance)\n",
    "5. [Feature Engineering](#feature)\n",
    "6. [Machine Learning Model](#model) \n",
    "7. [Next step](#next) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "###### The initial idea start from udacity DAND project and I expand to apply Feature Engineering and Ensemble model (Raindom Forest-Ensemble XGboost, NN and Pyspark) \n",
    "\n",
    "This dataset contains the records from 300,000 medical appointments in Brazil(from the previous dataset version on kaggle'2017). The dataset describes different characteristics of each appointment (rather than of each patient):  \n",
    "\n",
    "- Gender \n",
    "- ScheduledDay &mdash; the day when the patient scheduled their appointment \n",
    "- AppointmentDay- registeration date , appoinement date, awaiting time\n",
    "- Age\n",
    "- Scholarship &mdash; 1 if the patient is enrolled into Brazilian welfare program Bolsa Familia. \n",
    "- Hipertension, Diabetis, Alcoholism, Handcap, Smoke\n",
    "- SMS_received &mdash; whether a patient received an SMS before the appointment \n",
    "- Status; show, no show\n",
    "\n",
    "In this project, you will use data provided by [kaggle: project Medical Appointment NoShow](https://www.kaggle.com/joniarroba/noshowappointments)\n",
    "\n",
    "The goal is to explore what factors influence if the patient shows up for their appointment. What if that possible to predict someone to no-show an appointment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import xlim\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_recall_curve\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\Administrator\\\\Portfolio\\\\noshow.csv')\n",
    "\n",
    "# shape\n",
    "print(\"shape:\",data.shape,\"\\n\")\n",
    "\n",
    "# head\n",
    "print(\"First records of data:\\n\",data.head(),\"\\n\")\n",
    "\n",
    "#dtype data\n",
    "print(data.info())\n",
    "\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "## Data Wrangling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_vars1 = ['Gender', 'DayOfTheWeek', 'Scholarship',  'Sms_Reminder']\n",
    "discrete_vars2 = ['Diabetes','Alcoolism', 'HiperTension', 'Handcap', 'Smokes','Tuberculosis']\n",
    "continuous_vars = ['Age', 'AwaitingTime']\n",
    "frequency_visit_dicease = ['Diabetes','Alcoolism','Tuberculosis']\n",
    "non_freq_visit = ['Smokes','HiperTension']\n",
    "target_var = ['Status']\n",
    "\n",
    "class explore_data():\n",
    "    def __init__(self, discrete_vars1, discrete_vars2, continuous_vars):\n",
    "        self.discrete_var1 = data[discrete_vars1]\n",
    "        self.discrete_var2 = data[discrete_vars2]\n",
    "        self.continuous_vars = data[continuous_vars]\n",
    "\n",
    "        \n",
    "        \n",
    "    def _Con_fea_plots(self):\n",
    "              \n",
    "        figsize = (40,15)\n",
    "        for i, cv in enumerate(continuous_vars):\n",
    "            plt.subplot(1,2,i+1) \n",
    "            data[cv].value_counts().plot(kind='hist', title=cv)\n",
    "            plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "        for i, dv1 in enumerate(discrete_vars1):\n",
    "            plt.subplot(1,4,i+1) \n",
    "            data[dv1].value_counts().plot(kind='bar', title=dv1)\n",
    "            plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "        for i, dv2 in enumerate(discrete_vars2):\n",
    "            plt.subplot(2,3,i+1) \n",
    "            data[dv2].value_counts().plot(kind='bar', title=dv2)\n",
    "            plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "        for i, dv in enumerate(target_var):\n",
    "            plt.subplots()\n",
    "            data[dv].value_counts().plot(kind='bar', title=dv)\n",
    "            plt.ylabel('Frequency')\n",
    "        \n",
    "  \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleaning'></a>\n",
    "## Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data Cleaning \n",
    "\n",
    "# clean Age < 0\n",
    "print('remove %s rows that Age < 0 ' %(len(data[data['Age'] < 0])))\n",
    "\n",
    "data = data[data['Age'] >= 0]\n",
    "\n",
    "# Delete Handcap Col \n",
    "del data['Handcap']\n",
    "\n",
    "# Clean negative Awaiting time --Absolute to positive \n",
    "data['AwaitingTime'] = data['AwaitingTime'].apply(lambda x: abs(x))\n",
    "\n",
    "# categorial var\n",
    "DayOfWeek_Cat_encoded = {'Monday' : 0, 'Tuesday' : 1, 'Wednesday' : 2, 'Thursday' : 3, 'Friday' : 4, 'Saturday' : 5, 'Sunday' : 6}\n",
    "data['DayOfTheWeek'] = data['DayOfTheWeek'].map(DayOfWeek_Cat_encoded)\n",
    "\n",
    "# gender var \n",
    "encoder = LabelEncoder()\n",
    "data['Gender'] = encoder.fit_transform(data['Gender'])\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='EDA'></a>\n",
    "## Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between continuouse variables (Age vs AwaitingTime)\n",
    "# Assumption : Increase of Age may prone to more visit. \n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "scatter_matrix(data[continuous_vars],figsize=(12,8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[continuous_vars].describe())\n",
    "print(data[continuous_vars].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack graph- SMS reminder vs Status\n",
    "\n",
    "fig, axs = plt.subplots(0,1)\n",
    "data_dow_status = data.groupby(['Sms_Reminder', 'Status'])['Sms_Reminder'].count().unstack('Status')\n",
    "data_dow_status.plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_var2_NoHandicab = discrete_vars2.remove('Handcap')\n",
    "for index, col in enumerate (discrete_vars2):\n",
    "    fig = plt.subplot(2,3,index+1)\n",
    "    data_sickness_status = data.groupby([col,'Status'])[col].count().unstack('Status')\n",
    "    data_sickness_status.plot(kind='bar')\n",
    "    plt.xlabel(print(col))\n",
    "    plt.ylabel('frequency')\n",
    "    plt.title ('frequency of Show up to appointment By %s'%col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result :  increase number of SMS reminder does significant increase number of show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does day of the week effect number of show or no show\n",
    "\n",
    "fig, axs = plt.subplots(0,1)\n",
    "data_dow_status = data.groupby(['DayOfTheWeek', 'Status'])['DayOfTheWeek'].count().unstack('Status').fillna(0)\n",
    "data_dow_status.plot(kind='bar',stacked = True)\n",
    "plt.title('Frequency of people showing up and not showing up by Day of the week')\n",
    "plt.xlabel('Day of the week')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(('No-Show', 'Show-Up'),loc='upper right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption Does Age effect showing status \n",
    "plt.figure(figsize=(25,15))\n",
    "data.boxplot(column=['Age'], return_type='axes', by='Status')\n",
    "plt.xlabel('Status')\n",
    "plt.ylabel('Age')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10)) \n",
    "\n",
    "for i, status in enumerate(['Show-Up', 'No-Show']):\n",
    "    data_show = data[data['Status']==status]\n",
    "    for gen in [0, 1]:\n",
    "        plt.subplot(1, 2, i+1)\n",
    "        data_gender = data_show[data_show['Gender']==gen]\n",
    "        freq_age = data_gender['Age'].value_counts().sort_index()\n",
    "        freq_age.plot()\n",
    "        plt.title('Age frequency by gender: %s '%status)\n",
    "        plt.xlabel('Age')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend(('Female','Male'),loc='upper right')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Datetime Variable\n",
    "for col in ['AppointmentRegistration', 'ApointmentData']:\n",
    "    for i, date in enumerate(['year', 'month', 'day']):\n",
    "        data['%s_%s'%(col, date)] = data[col].apply(lambda x: int(x.split('T')[0].split('-')[i]))\n",
    "    for i, time in enumerate(['hour', 'min', 'sec']):\n",
    "        data['%s_%s'%('AppointmentRegistration', time)] = data['AppointmentRegistration'].apply(lambda x: int(x.split('T')[1][:-1].split(':')[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appointment by time (initial time series analysis)\n",
    "np.array(data[data['AppointmentRegistration_year']==2013].AppointmentRegistration_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10)) \n",
    "\n",
    "for i, year in enumerate ([2013,2014,2015]):\n",
    "\n",
    "    #xi = np.array(data[data['AppointmentRegistration_year']==year].AppointmentRegistration_month)\n",
    "    #print(xi)\n",
    "   # print(xi.shape)\n",
    "    applointment_year = data[data['AppointmentRegistration_year']==year].AppointmentRegistration_month.value_counts().sort_index()\n",
    "    # plotting the line 1 points \n",
    "    applointment_year.plot(label = \"Year %s\" %year)\n",
    "    plt.legend()\n",
    "plt.xlabel('month')\n",
    "    # Set the y axis label of the current axis.\n",
    "plt.ylabel('appointment')\n",
    "    # Set a title of the current axes.\n",
    "plt.title('xxxx ')\n",
    "plt.xlim(1,12)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review output \n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10)) \n",
    "\n",
    "day = np.array(range(1,31,1))\n",
    "\n",
    "applointment_day = data.AppointmentRegistration_day.value_counts().sort_index()\n",
    "    # plotting the line 1 points \n",
    "applointment_day.plot()\n",
    "plt.xlabel('day')\n",
    "    # Set the y axis label of the current axis.\n",
    "plt.ylabel('appointment')\n",
    "    # Set a title of the current axes.\n",
    "plt.title('xxxx ')\n",
    "plt.xlim(1,31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : further Analysis / we can do time series analysis to see the pattern of seasoning / weekend or weekday may effect show or noshow status ---> in order to manage resource during the holiday (if it a gov : aim to manage cost / if it a private hos -->aim to promote new service during...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='performance'></a>\n",
    "## Define Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(model, x_train, y_train, y_test, y_pred):\n",
    "    \n",
    "    # Test options and evaluation metric\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "models = []\n",
    "models.append(('LRG', LogisticRegression()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('DTC', DecisionTreeClassifier()))\n",
    "\n",
    "\n",
    "# evaluate each model with 'Accuracy Score' and 'ROC AUC score'\n",
    "\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "        cv_results = model_selection.cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "\n",
    "\n",
    "        print 'Model name: %s'%model\n",
    "        print 'Test accuracy (Accuracy Score): %f'%metrics.accuracy_score(y_test, y_pred)\n",
    "        print 'Test accuracy (ROC AUC Score): %f'%metrics.roc_auc_score(y_test, y_pred)\n",
    "        print 'Train accuracy: %f'%clf.score(x_train, y_train)\n",
    "\n",
    "        fpr, tpr, thresholds = metrics.precision_recall_curve(y_test, y_pred)\n",
    "        print 'Area Under the Precision-Recall Curve: %f'%metrics.auc(fpr, tpr)\n",
    "\n",
    "        false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "        roc_auc = metrics.auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b',label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.2])\n",
    "plt.ylim([-0.1,1.2])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "## Machine Learning Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=1)\n",
    "\n",
    "#create model shells\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for mode_name in models:\n",
    "    return model_performance(model_name, x_train, y_train, y_test, y_pred)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose random forest to be baseline model\n",
    "Baseline RF Model Evaluation (ROC AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits of Tree-Based Models\n",
    "1. Works for both classification and regression\n",
    "2. Handles categorical features naturally\n",
    "3. No assumption of distributions\n",
    "4. Can handle non-linear interactions \n",
    "5. No need for feature scaling / transformation\n",
    "6. Handles missing values in the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rfc = RandomForestClassifier(oob_score=True, random_state=42)\n",
    "clf_rfc.fit(x_train,y_train)\n",
    "print(\"The Out-of-bag Score is:\", clf_rfc.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3.5))\n",
    "feat = pd.Series(clf_rfc.feature_importances_, index=x_df.columns)\n",
    "print(feat)\n",
    "feat.sort_values(ascending=True, inplace = True)\n",
    "fig,ax = plt.subplots(1,2)\n",
    "feat.plot(kind='barh')\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_important = ['AwaitingTime','DayOfTheWeek','Gender','Age','AppointmentRegistration_sec']\n",
    "x_fea = np.array(data[feature_important])\n",
    "y_fea = np.array(data['Status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train_fea, x_test_fea, y_train_fea, y_test_fea = train_test_split(x_fea, y_fea, test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rfc = RandomForestClassifier(oob_score=True, random_state=42)\n",
    "clf_rfc.fit(x_train_fea,y_train_fea)\n",
    "print(\"The Out-of-bag Score is:\", clf_rfc.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve model scoring with Ensemble XGBoost Algorithm \n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from sklearn.ensemble.partial_dependence import partial_dependence, plot_partial_dependence\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "feature_important = ['Age','Gender','DayOfTheWeek','AwaitingTime']\n",
    "\n",
    "my_imputer = Imputer()\n",
    "imputed_appt_x = my_imputer.fit_transform(x_train)\n",
    "\n",
    "clf.fit(imputed_appt_x, y_train)\n",
    "fig,ax = plt.subplots(figsize=(10,7))\n",
    "plot_partial_dependence(clf, imputed_appt_x, features= ['Age','Gender','DayOfTheWeek','AwaitingTime'],\n",
    "                                     feature_names=feature_important,\n",
    "                                       n_jobs=3, grid_resolution=50)\n",
    "display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='next'></a>\n",
    "## Next step\n",
    "\n",
    "##### improve model scoring\n",
    "1. handtune param_grid to get range of each parameter\n",
    "2. use GridSearchCV find best model \n",
    "3. get best model score \n",
    "\n",
    "\n",
    "##### work same dataset with others learning platform (Pyspark and NN net) \n",
    "\n",
    "1. apply this project on Spark (databricks community edition) \n",
    "2. Apply same project to deep learning.  \n",
    "4. Hyperparameter model tuning. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parameters\n",
    "param_grid = {\"max_depth\": [2,3,10],\n",
    "              \"max_features\" : [1.0,0.3,0.1],\n",
    "              \"min_samples_leaf\" : [3,5,9],\n",
    "              \"n_estimators\": [50,100,300],\n",
    "              \"learning_rate\": [0.05,0.1,0.02,0.2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Grid Search \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs_cv = GridSearchCV(model, param_grid=param_grid, cv = 3, verbose=10, n_jobs=-1 ).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparmeter setting\n",
    "gs_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=3, max_features=1.0, min_child_weight=1,\n",
    "       min_samples_leaf=3, missing=None, n_estimators=300, n_jobs=1,\n",
    "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "       subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create eval_set\n",
    "eval_set = [(X_train_2, y_train_2), (X_test_2, y_test_2)]\n",
    "\n",
    "# Fit our model to the training set\n",
    "best_model.fit(X_train_2, y_train_2, eval_set=eval_set, verbose=False)\n",
    "\n",
    "# Make predictions with test data\n",
    "y_pred = best_model.predict(X_test_2)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "# Retrieve performance metrics\n",
    "results = best_model.evals_result()\n",
    "epochs = len(results['validation_0']['rmse'])\n",
    "x_axis = range(0, epochs)\n",
    "\n",
    "# Plot log loss curve\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, results['validation_0']['rmse'], label='Train')\n",
    "ax.plot(x_axis, results['validation_1']['rmse'], label='Test')\n",
    "ax.legend()\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('XGBoost RMSE')\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot basic feature importance chart\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "xgb.plot_importance(best_model, height=0.5, ax=ax)\n",
    "display(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "name": "Project_noshow",
  "notebookId": 677130702450198
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
